{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267ac127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset_root = '4-condition-splited-data'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),         \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=dataset_root + '/train', transform=transform)\n",
    "test_dataset = ImageFolder(root=dataset_root + '/test', transform=transform)\n",
    "val_dataset = ImageFolder(root=dataset_root+\"/validation\",transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6cb7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size*2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size*2, hidden_size*4)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchNormalization1 = nn.BatchNorm1d(hidden_size*4) \n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size*4, hidden_size * 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batchNormalization2 = nn.BatchNorm1d(hidden_size) \n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc5 = nn.Linear(hidden_size , hidden_size)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(hidden_size , num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchNormalization1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.batchNormalization2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb670bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Loss: 0.5764099955558777\n",
      "Test Loss: 0.04865653576824862, Test Accuracy: 72.61538461538461%\n",
      "Epoch [2/30], Training Loss: 0.6758427023887634\n",
      "Test Loss: 0.026439272461918732, Test Accuracy: 77.12820512820512%\n",
      "Epoch [3/30], Training Loss: 0.14143046736717224\n",
      "Test Loss: 0.03448500877771622, Test Accuracy: 72.0%\n",
      "Epoch [4/30], Training Loss: 0.45798543095588684\n",
      "Test Loss: 0.029863370323899942, Test Accuracy: 75.28205128205127%\n",
      "Epoch [5/30], Training Loss: 0.23185260593891144\n",
      "Test Loss: 0.04224155299332685, Test Accuracy: 77.33333333333333%\n",
      "Epoch [6/30], Training Loss: 2.067793130874634\n",
      "Test Loss: 0.028563487768555298, Test Accuracy: 78.35897435897435%\n",
      "Epoch [7/30], Training Loss: 0.2949659824371338\n",
      "Test Loss: 0.3283256766090814, Test Accuracy: 72.2051282051282%\n",
      "Epoch [8/30], Training Loss: 0.25663161277770996\n",
      "Test Loss: 0.1933996559078029, Test Accuracy: 77.94871794871796%\n",
      "Epoch [9/30], Training Loss: 0.8471630811691284\n",
      "Test Loss: 0.02960306544525501, Test Accuracy: 76.2051282051282%\n",
      "Epoch [10/30], Training Loss: 0.7480639219284058\n",
      "Test Loss: 0.03431522823553771, Test Accuracy: 75.07692307692308%\n",
      "Epoch [11/30], Training Loss: 0.24855424463748932\n",
      "Test Loss: 2.108780105136908, Test Accuracy: 69.23076923076923%\n",
      "Epoch [12/30], Training Loss: 0.475835382938385\n",
      "Test Loss: 0.031287071611075544, Test Accuracy: 79.58974358974359%\n",
      "Epoch [13/30], Training Loss: 0.22616548836231232\n",
      "Test Loss: 0.027467382893739387, Test Accuracy: 80.92307692307692%\n",
      "Epoch [14/30], Training Loss: 0.5259239077568054\n",
      "Test Loss: 0.03255920913607742, Test Accuracy: 78.05128205128206%\n",
      "Epoch [15/30], Training Loss: 0.6512917280197144\n",
      "Test Loss: 0.037408306351653896, Test Accuracy: 75.07692307692308%\n",
      "Epoch [16/30], Training Loss: 0.20329774916172028\n",
      "Test Loss: 0.38363273329101505, Test Accuracy: 67.38461538461539%\n",
      "Epoch [17/30], Training Loss: 0.6163487434387207\n",
      "Test Loss: 0.032475319609332545, Test Accuracy: 74.97435897435898%\n",
      "Epoch [18/30], Training Loss: 0.3755168616771698\n",
      "Test Loss: 0.026744746304451464, Test Accuracy: 78.56410256410257%\n",
      "Epoch [19/30], Training Loss: 0.2056799679994583\n",
      "Test Loss: 0.033280890502217705, Test Accuracy: 73.64102564102564%\n",
      "Epoch [20/30], Training Loss: 0.18714503943920135\n",
      "Test Loss: 0.03353161853093367, Test Accuracy: 74.97435897435898%\n",
      "Epoch [21/30], Training Loss: 0.29155436158180237\n",
      "Test Loss: 0.034569834004848816, Test Accuracy: 73.64102564102564%\n",
      "Epoch [22/30], Training Loss: 1.2587248086929321\n",
      "Test Loss: 0.04541922968072005, Test Accuracy: 70.56410256410255%\n",
      "Epoch [23/30], Training Loss: 0.3656240403652191\n",
      "Test Loss: 0.02970425718678878, Test Accuracy: 79.07692307692308%\n",
      "Epoch [24/30], Training Loss: 0.4502505660057068\n",
      "Test Loss: 0.04051438972616616, Test Accuracy: 72.71794871794872%\n",
      "Epoch [25/30], Training Loss: 0.8982685804367065\n",
      "Test Loss: 0.04497592193671526, Test Accuracy: 74.87179487179488%\n",
      "Epoch [26/30], Training Loss: 0.296934574842453\n",
      "Test Loss: 0.030582613371109638, Test Accuracy: 78.35897435897435%\n",
      "Epoch [27/30], Training Loss: 0.06566648930311203\n",
      "Test Loss: 0.10095700494610728, Test Accuracy: 78.46153846153847%\n",
      "Epoch [28/30], Training Loss: 0.12654192745685577\n",
      "Test Loss: 0.08068911633334863, Test Accuracy: 67.48717948717949%\n",
      "Epoch [29/30], Training Loss: 0.25232434272766113\n",
      "Test Loss: 0.28570037617586935, Test Accuracy: 74.56410256410257%\n",
      "Epoch [30/30], Training Loss: 0.4147215187549591\n",
      "Test Loss: 0.036200471453619404, Test Accuracy: 76.51282051282051%\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = (224,224,3)\n",
    "\n",
    "W,H,C = INPUT_SIZE\n",
    "input_size = W*H*C\n",
    "model = NeuralNetwork(input_size,64,len(train_dataset.classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item()}')\n",
    "\n",
    "    # Test the model after each epoch\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    accuracy = correct / len(val_loader.dataset) * 100.0\n",
    "\n",
    "    print(f'Test Loss: {test_loss}, Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3215e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.4421350359916687\n",
      "Test Loss: 0.028997600871400957, Test Accuracy: 75.6923076923077%\n",
      "Epoch [2/10], Training Loss: 0.2250380963087082\n",
      "Test Loss: 0.07001385190930122, Test Accuracy: 76.92307692307693%\n",
      "Epoch [3/10], Training Loss: 0.4766378104686737\n",
      "Test Loss: 0.06376167546960716, Test Accuracy: 72.3076923076923%\n",
      "Epoch [4/10], Training Loss: 0.3085119426250458\n",
      "Test Loss: 0.026896507984194427, Test Accuracy: 77.84615384615384%\n",
      "Epoch [5/10], Training Loss: 0.20064136385917664\n",
      "Test Loss: 0.07991344497377913, Test Accuracy: 75.07692307692308%\n",
      "Epoch [6/10], Training Loss: 0.2544028162956238\n",
      "Test Loss: 0.05740471358721455, Test Accuracy: 77.43589743589745%\n",
      "Epoch [7/10], Training Loss: 0.23519614338874817\n",
      "Test Loss: 0.029940469166320045, Test Accuracy: 76.1025641025641%\n",
      "Epoch [8/10], Training Loss: 0.9575773477554321\n",
      "Test Loss: 0.034981960750734196, Test Accuracy: 76.71794871794872%\n",
      "Epoch [9/10], Training Loss: 1.146174669265747\n",
      "Test Loss: 0.6045322306330005, Test Accuracy: 33.64102564102564%\n",
      "Epoch [10/10], Training Loss: 0.3325631618499756\n",
      "Test Loss: 0.02852905013856705, Test Accuracy: 77.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = (224,224,3)\n",
    "\n",
    "W,H,C = INPUT_SIZE\n",
    "input_size = W*H*C\n",
    "model = NeuralNetwork(input_size,64,len(train_dataset.classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item()}')\n",
    "\n",
    "    # Test the model after each epoch\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    accuracy = correct / len(val_loader.dataset) * 100.0\n",
    "\n",
    "    print(f'Test Loss: {test_loss}, Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9500c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ann-condition-4-fit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073557a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
