{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b3895d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset_root = '1-condition-splited-data'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),         \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=dataset_root + '/train', transform=transform)\n",
    "test_dataset = ImageFolder(root=dataset_root + '/test', transform=transform)\n",
    "val_dataset = ImageFolder(root=dataset_root+\"/validation\",transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "178fca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Assuming you have defined your model architecture\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)  # Assuming 3 output classes\n",
    "\n",
    "# Specify the path to the saved weights file\n",
    "saved_weights_path = \"transfer-learning-condition-1-fit.pth\"\n",
    "\n",
    "# Load the saved weights into the model\n",
    "model.load_state_dict(torch.load(saved_weights_path))\n",
    "\n",
    "# Set the model to evaluation mode (if needed)\n",
    "model.eval()\n",
    "\n",
    "# Now, you can use the loaded model for predictions or further training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "881a7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0037263852877852817, Test Accuracy: 96.39999999999999%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_labels += labels.cpu().numpy().tolist()\n",
    "        all_predictions += predicted.cpu().numpy().tolist()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = correct / len(test_loader.dataset) * 100.0\n",
    "\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c94b5105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0037\n",
      "Test Accuracy : 96.4000\n",
      "Precision: 0.9642\n",
      "Recall : 0.9640\n",
      "F1 Score : 0.9640\n",
      "Confusion Matrix:\n",
      "[[959   4  37]\n",
      " [  1 999   0]\n",
      " [ 66   0 934]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "           2       0.96      0.93      0.95      1000\n",
      "\n",
      "    accuracy                           0.96      3000\n",
      "   macro avg       0.96      0.96      0.96      3000\n",
      "weighted avg       0.96      0.96      0.96      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy,  Precision, Recall ve F1 skoru, Karmaşıklık Matrisi, Classification Report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f\"Test Accuracy : {accuracy:.4f}\")\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f\"Recall : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_predictions, target_names=[str(i) for i in range(len(test_dataset.classes))]))\n",
    "\n",
    "sns.heatmap(cm, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638a658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
